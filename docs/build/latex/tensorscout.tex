%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsible pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}

\PassOptionsToPackage{booktabs}{sphinx}
\PassOptionsToPackage{colorrows}{sphinx}

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{tgtermes}
\usepackage{tgheros}
\renewcommand{\ttdefault}{txtt}



\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=auto}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}


\usepackage{sphinxmessages}




\title{tensorscout}
\date{Apr 02, 2023}
\release{2.0}
\author{Andrew Garcia, Ph.D.\@{}}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\ifdefined\shorthandoff
  \ifnum\catcode`\=\string=\active\shorthandoff{=}\fi
  \ifnum\catcode`\"=\active\shorthandoff{"}\fi
\fi

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}



\chapter{What if for some reason, you could unlock 100\% of your computing processing power?}
\label{\detokenize{index:what-if-for-some-reason-you-could-unlock-100-of-your-computing-processing-power}}
\sphinxAtStartPar
\sphinxhref{https://github.com/andrewrgarcia/tensorscout}{\sphinxincludegraphics[width=100\sphinxpxdimen]{{icon_scout}.png}}

\sphinxAtStartPar
The Python package is designed for tensor operations and is optimized for parallel processing.

\sphinxAtStartPar
One of the key features of this package is its support for parallel processing.
It includes decorators powered by \sphinxhref{https://pathos.readthedocs.io}{pathos} that allow users to distribute operations over multiple CPU cores or vCPUs
(with cloud computing),
significantly reducing the time required for computation. Specifically, these decorators allow users to partition arrays into sectors and allocate
operations for each sector over the defined available cores. The package currently does not include support for GPUs for faster processing,
thought it may be a desired feature for the future.

\sphinxAtStartPar
Overall, this package is ideal for users working with large\sphinxhyphen{}scale tensor operations and seeking to optimize performance through parallel processing.

\sphinxAtStartPar
Check out the {\hyperref[\detokenize{usage::doc}]{\sphinxcrossref{\DUrole{doc}{Usage}}}} section for further information, including how to {\hyperref[\detokenize{usage:installation}]{\sphinxcrossref{\DUrole{std,std-ref}{Installation}}}} the project.

\noindent\sphinxincludegraphics[width=300\sphinxpxdimen]{{parallel16}.png}


\section{Colab Notebook}
\label{\detokenize{index:colab-notebook}}
\sphinxAtStartPar
In progress

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{colaboratory}.png}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
This project is under active development.
\end{sphinxadmonition}


\chapter{Contents}
\label{\detokenize{index:contents}}
\sphinxstepscope


\section{Usage}
\label{\detokenize{usage:usage}}\label{\detokenize{usage::doc}}

\subsection{Installation}
\label{\detokenize{usage:installation}}\label{\detokenize{usage:id1}}
\sphinxAtStartPar
It is recommended you use voxelmap through a virtual environment. You may follow the below simple protocol to create the virtual environment, run it, and install the package there:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZdl{} }virtualenv\PYG{+w}{ }venv
\PYG{g+gp}{\PYGZdl{} }\PYG{n+nb}{source}\PYG{+w}{ }venv/bin/activate
\PYG{g+gp+gpVirtualEnv}{(.venv)} \PYG{g+gp}{\PYGZdl{} }pip\PYG{+w}{ }install\PYG{+w}{ }tensorscout
\end{sphinxVerbatim}

\sphinxAtStartPar
To exit the virtual environment, simply type \sphinxcode{\sphinxupquote{deactivate}}. To access it at any other time again, enter with the above \sphinxcode{\sphinxupquote{source}} command.


\subsection{Monte Carlo sampling with multiple processors}
\label{\detokenize{usage:monte-carlo-sampling-with-multiple-processors}}
\sphinxAtStartPar
When performing Monte Carlo sampling at a high number, it can significantly impact computing power.
To address this, we have developed the \sphinxcode{\sphinxupquote{@multicarlo}} decorator, which allocates a specific number of iterations to
a defined number of available processors or cores. In our case, since we have a computer with 4 cores, we have set
the num\_cores to 4. However, you can set it to as many cores as your computer or server may have available.

\sphinxAtStartPar
In this example, we compare the runtime performance of this multiprocessing decorator with the bare approach,
which uses a single core. We begin by importing all the required modules and defining a function that is used
in both approaches to avoid redundancy.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{tensorscout} \PYG{k}{as} \PYG{n+nn}{scout}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{k+kn}{from} \PYG{n+nn}{timethis} \PYG{k+kn}{import} \PYG{n}{timethis}

\PYG{k}{def} \PYG{n+nf}{make\PYGZus{}histograms}\PYG{p}{(}\PYG{n}{results}\PYG{p}{,} \PYG{n}{title}\PYG{p}{)}\PYG{p}{:}
   \PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{p}{)}
   \PYG{n}{plt}\PYG{o}{.}\PYG{n}{title}\PYG{p}{(}\PYG{n}{title}\PYG{o}{+}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{(N = 100,000)}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
   \PYG{n}{plt}\PYG{o}{.}\PYG{n}{hist}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
   \PYG{n}{plt}\PYG{o}{.}\PYG{n}{hist}\PYG{p}{(}\PYG{n}{results}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{n}{label}\PYG{o}{=}\PYG{n}{title}\PYG{p}{)}
   \PYG{n}{plt}\PYG{o}{.}\PYG{n}{legend}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
The operations we run on both methodologies are random sampling operations which take random numbers from a distribution.
For both methods, we set the number of samples to 100,000, which is a considerable amount.
In the following code block, we apply the \sphinxcode{\sphinxupquote{@multicarlo}} decorator to our random sampling function \sphinxcode{\sphinxupquote{monte\_carlo\_function}}
and distribute the sampling iterations across four cores.

\sphinxAtStartPar
The \sphinxcode{\sphinxupquote{timethis()}} function is used to record the run times of both methods and print them as a terminal output.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{title} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data resampling (with @multicarlo \PYGZhy{}\PYGZhy{} 4 cores)}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{k}{with} \PYG{n}{timethis}\PYG{p}{(}\PYG{n}{title}\PYG{p}{)}\PYG{p}{:}

   \PYG{n+nd}{@scout}\PYG{o}{.}\PYG{n}{multicarlo}\PYG{p}{(}\PYG{n}{num\PYGZus{}iters}\PYG{o}{=}\PYG{l+m+mi}{100000}\PYG{p}{,} \PYG{n}{num\PYGZus{}cores}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{)}
   \PYG{k}{def} \PYG{n+nf}{monte\PYGZus{}carlo\PYGZus{}function}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,} \PYG{o}{*}\PYG{n}{args}\PYG{p}{,} \PYG{o}{*}\PYG{o}{*}\PYG{n}{kwargs}\PYG{p}{)}\PYG{p}{:}
      \PYG{n}{simulated\PYGZus{}data} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{n}{data}\PYG{p}{)}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{std}\PYG{p}{(}\PYG{n}{data}\PYG{p}{)}\PYG{p}{)}
      \PYG{k}{return} \PYG{n}{simulated\PYGZus{}data}

   \PYG{n}{data} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1000}\PYG{p}{)}
   \PYG{n}{results} \PYG{o}{=} \PYG{n}{monte\PYGZus{}carlo\PYGZus{}function}\PYG{p}{(}\PYG{n}{data}\PYG{p}{)}
   \PYG{n}{make\PYGZus{}histograms}\PYG{p}{(}\PYG{n}{results}\PYG{p}{,}\PYG{n}{title}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
The following code block executes the same tasks as the previous block, but using a bare approach,
meaning that it uses a single core to perform all 100,000 random samples.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{title}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data resampling (bare)}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{k}{with} \PYG{n}{timethis}\PYG{p}{(}\PYG{n}{title}\PYG{p}{)}\PYG{p}{:}

   \PYG{k}{def} \PYG{n+nf}{monte\PYGZus{}carlo\PYGZus{}function\PYGZus{}bare}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,} \PYG{o}{*}\PYG{n}{args}\PYG{p}{,} \PYG{o}{*}\PYG{o}{*}\PYG{n}{kwargs}\PYG{p}{)}\PYG{p}{:}
      \PYG{n}{simulated\PYGZus{}data} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{mean}\PYG{p}{(}\PYG{n}{data}\PYG{p}{)}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{std}\PYG{p}{(}\PYG{n}{data}\PYG{p}{)}\PYG{p}{)}
      \PYG{k}{return} \PYG{n}{simulated\PYGZus{}data}

   \PYG{n}{data} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1000}\PYG{p}{)}
   \PYG{n}{results} \PYG{o}{=} \PYG{p}{[}\PYG{n}{monte\PYGZus{}carlo\PYGZus{}function\PYGZus{}bare}\PYG{p}{(}\PYG{n}{data}\PYG{p}{)} \PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{100000}\PYG{p}{)}\PYG{p}{]}
   \PYG{n}{make\PYGZus{}histograms}\PYG{p}{(}\PYG{n}{results}\PYG{p}{,}\PYG{n}{title}\PYG{p}{)}

\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
The output for the previous three code blocks is displayed below.

\sphinxAtStartPar
\sphinxincludegraphics[width=320\sphinxpxdimen]{{multicarlo}.png} \sphinxincludegraphics[width=320\sphinxpxdimen]{{bare_multicarlo}.png}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{p}{[}\PYG{n}{OUT}\PYG{p}{]}
\PYG{g+go}{monte carlo resampling (with @multicarlo \PYGZhy{}\PYGZhy{} 4 cores): 2.812 seconds}
\PYG{g+go}{monte carlo resampling (bare): 4.328 seconds}
\end{sphinxVerbatim}

\sphinxAtStartPar
Both approaches produce a similar random sampling distribution outcome,
but the \sphinxcode{\sphinxupquote{@multicarlo}} decorated function that uses multiprocessing on 4 cores shows around 50\% better runtime performance.


\subsection{Parallel Computation on Sectorized Matrices using Multiprocessing}
\label{\detokenize{usage:parallel-computation-on-sectorized-matrices-using-multiprocessing}}
\sphinxAtStartPar
\sphinxhref{https://github.com/andrewrgarcia/voxelmap}{\sphinxincludegraphics[width=300\sphinxpxdimen]{{cakerun_concept}.png}} \sphinxhref{https://github.com/andrewrgarcia/voxelmap}{\sphinxincludegraphics[width=300\sphinxpxdimen]{{coik}.jpg}}

\sphinxAtStartPar
The question of whether it’s faster to eat a cake alone or have 100 people cut a slice and eat their portions until
it’s gone highlights the main concept behind the cakerun decorator.
Essentially, the decorator partitions an array into a specified number of equally\sphinxhyphen{}sized sectors and performs
the same task on all sectors in parallel.

\sphinxAtStartPar
In this example, we set the number of cores to 4 and compare the performance of using multiprocessing versus
using a single core. Before proceeding, we import all necessary modules and define the draw function which is
used in both approaches to avoid redundancy. Additionally, we define the initial matrix, which is a 252 x 252 matrix of 1s,
that will be operated on by both methodologies.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{tensorscout} \PYG{k}{as} \PYG{n+nn}{scout}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{k+kn}{from} \PYG{n+nn}{timethis} \PYG{k+kn}{import} \PYG{n}{timethis}

\PYG{n}{num\PYGZus{}iters} \PYG{o}{=} \PYG{l+m+mi}{40000}

\PYG{k}{def} \PYG{n+nf}{draw}\PYG{p}{(}\PYG{n}{result}\PYG{p}{)}\PYG{p}{:}
   \PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{p}{)}
   \PYG{n}{plt}\PYG{o}{.}\PYG{n}{title}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+s1}{ \PYGZhy{}\PYGZhy{} \PYGZdl{}N\PYGZus{}}\PYG{l+s+s1}{\PYGZob{}\PYGZob{}}\PYG{l+s+s1}{perforated\PYGZcb{}\PYGZcb{}\PYGZdl{} = }\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{o}{.}\PYG{n}{format}\PYG{p}{(}\PYG{n}{title}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{multiply}\PYG{p}{(}\PYG{o}{*}\PYG{n}{result}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{)} \PYG{o}{\PYGZhy{}} \PYG{n}{np}\PYG{o}{.}\PYG{n}{count\PYGZus{}nonzero}\PYG{p}{(}\PYG{n}{result}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
   \PYG{n}{plt}\PYG{o}{.}\PYG{n}{imshow}\PYG{p}{(}\PYG{n}{result}\PYG{p}{,}\PYG{n}{cmap}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{bone}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}


\PYG{n}{matrix} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{ones}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{252}\PYG{p}{,}\PYG{l+m+mi}{252}\PYG{p}{)}\PYG{p}{)}

\PYG{n}{plt}\PYG{o}{.}\PYG{n}{imshow}\PYG{p}{(}\PYG{n}{matrix}\PYG{p}{,}\PYG{n}{cmap}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{bone}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{title}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{initial canvas}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics[width=320\sphinxpxdimen]{{black_canvas}.png}

\sphinxAtStartPar
In this example, the initial matrix is composed entirely of 1s and will appear as a single color when drawn.
The purpose of this code is to apply an operation called “perforation” to the matrix. At each iteration,
a random x\sphinxhyphen{}y coordinate is selected and the value at that location is set to 0.

\sphinxAtStartPar
The first case demonstrates the use of the \sphinxcode{\sphinxupquote{@cakerun}} decorator to split the matrix into sectors and apply
the perforate function to each sector. The former code block specifies 40,000 perforating iterations, which for the case
of this aprroach has them evenly distributed across the 4 sectors, resulting in 10,000 iterations per sector, ocurring simultaneously.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{title} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{cakerun MP (4 cores)}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{k}{with} \PYG{n}{timethis}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{o}{.}\PYG{n}{format}\PYG{p}{(}\PYG{n}{title}\PYG{p}{)}\PYG{p}{)}\PYG{p}{:}

   \PYG{n}{cores} \PYG{o}{=} \PYG{l+m+mi}{4}
   \PYG{n+nd}{@scout}\PYG{o}{.}\PYG{n}{cakerun}\PYG{p}{(}\PYG{n}{num\PYGZus{}cores}\PYG{o}{=}\PYG{n}{cores}\PYG{p}{,} \PYG{n}{L\PYGZus{}sectors}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{)}
   \PYG{k}{def} \PYG{n+nf}{perforate}\PYG{p}{(}\PYG{n}{sector}\PYG{p}{)}\PYG{p}{:}

      \PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{num\PYGZus{}iters} \PYG{o}{/}\PYG{o}{/} \PYG{n}{cores}\PYG{p}{)}\PYG{p}{:}
            \PYG{n}{cds} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{argwhere}\PYG{p}{(}\PYG{n}{sector}\PYG{o}{!=}\PYG{l+m+mi}{0}\PYG{p}{)}
            \PYG{n}{sector}\PYG{p}{[}\PYG{n+nb}{tuple}\PYG{p}{(}\PYG{n}{cds}\PYG{p}{[}\PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{randint}\PYG{p}{(}\PYG{n}{cds}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}\PYG{p}{]}\PYG{p}{)}\PYG{p}{]} \PYG{o}{=} \PYG{l+m+mi}{0}
      \PYG{k}{return} \PYG{n}{sector}

   \PYG{n}{result} \PYG{o}{=} \PYG{n}{perforate}\PYG{p}{(}\PYG{n}{matrix}\PYG{p}{)}
   \PYG{n}{draw}\PYG{p}{(}\PYG{n}{result}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
In the next code block, the perforating operation is applied for 40,000 iterations using a bare approach with a single processor.
Hence, there is no task split involved.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{title} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{single core}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{k}{with} \PYG{n}{timethis}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{o}{.}\PYG{n}{format}\PYG{p}{(}\PYG{n}{title}\PYG{p}{)}\PYG{p}{)}\PYG{p}{:}

   \PYG{k}{def} \PYG{n+nf}{perforate\PYGZus{}bare}\PYG{p}{(}\PYG{n}{sector}\PYG{p}{)}\PYG{p}{:}
      \PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{num\PYGZus{}iters}\PYG{p}{)}\PYG{p}{:}
            \PYG{n}{cds} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{argwhere}\PYG{p}{(}\PYG{n}{sector}\PYG{o}{!=}\PYG{l+m+mi}{0}\PYG{p}{)}
            \PYG{n}{sector}\PYG{p}{[}\PYG{n+nb}{tuple}\PYG{p}{(}\PYG{n}{cds}\PYG{p}{[}\PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{randint}\PYG{p}{(}\PYG{n}{cds}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}\PYG{p}{]}\PYG{p}{)}\PYG{p}{]} \PYG{o}{=} \PYG{l+m+mi}{0}
      \PYG{k}{return} \PYG{n}{sector}


   \PYG{n}{result} \PYG{o}{=} \PYG{n}{perforate\PYGZus{}bare}\PYG{p}{(}\PYG{n}{matrix}\PYG{p}{)}
   \PYG{n}{draw}\PYG{p}{(}\PYG{n}{result}\PYG{p}{)}


\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
The following are graphical and runtime comparisons of both methods:

\sphinxAtStartPar
\sphinxincludegraphics[width=320\sphinxpxdimen]{{cakerun}.png} \sphinxincludegraphics[width=320\sphinxpxdimen]{{bare_cakerun}.png}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{p}{[}\PYG{n}{OUT}\PYG{p}{]}
\PYG{g+go}{cakerun MP (4 cores): 2.968 seconds}
\PYG{g+go}{single core: 25.868 seconds}
\end{sphinxVerbatim}

\sphinxAtStartPar
It is apparent that both approaches yield a similar outcome and have
the same number of perforations. However, the \sphinxcode{\sphinxupquote{@cakerun}} decorated function, which uses four
cores simultaneously, has a runtime that is 8\sphinxhyphen{}9 times faster than the bare approach.

\sphinxstepscope


\section{API Reference}
\label{\detokenize{api:api-reference}}\label{\detokenize{api::doc}}

\subsection{Global Methods}
\label{\detokenize{api:global-methods}}
\sphinxAtStartPar
At the time, tensorscout is a lean module composed of only 2 decorators.
\index{multicarlo (class in tensorscout)@\spxentry{multicarlo}\spxextra{class in tensorscout}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{api:tensorscout.multicarlo}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{tensorscout.}}\sphinxbfcode{\sphinxupquote{multicarlo}}}{\emph{\DUrole{n}{num\_iters}}, \emph{\DUrole{n}{num\_cores}}}{}
\pysigstopsignatures
\sphinxAtStartPar
This decorator performs a non\sphinxhyphen{}dynamic operation or task for a specified number of iterations num\_iters and distributes the tasks across a requested number of available processors num\_cores.


\subsubsection{Parameters}
\label{\detokenize{api:parameters}}\begin{description}
\sphinxlineitem{num\_cores: int}
\sphinxAtStartPar
Number of processors to use

\sphinxlineitem{num\_iters}{[}int{]}
\sphinxAtStartPar
The number of iterations to perform for a specific model / Monte Carlo simulation.

\end{description}

\end{fulllineitems}

\index{cakerun (class in tensorscout)@\spxentry{cakerun}\spxextra{class in tensorscout}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{api:tensorscout.cakerun}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{tensorscout.}}\sphinxbfcode{\sphinxupquote{cakerun}}}{\emph{\DUrole{n}{num\_cores}}, \emph{\DUrole{n}{L\_sectors}}}{}
\pysigstopsignatures
\sphinxAtStartPar
This decorator partitions an array into sectors and applies a given function to each sector in parallel. The result of each computation is merged into a final output array.


\subsubsection{Parameters}
\label{\detokenize{api:id1}}\begin{description}
\sphinxlineitem{num\_cores: int}
\sphinxAtStartPar
Number of processors to use

\sphinxlineitem{L\_sectors}{[}int{]}
\sphinxAtStartPar
The length scale for the number of sectors {[}per column{]}. For non\sphinxhyphen{}square arrays, the number of sectors per row gets adjusted as a function of this value

\end{description}

\end{fulllineitems}




\renewcommand{\indexname}{Index}
\printindex
\end{document}